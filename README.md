# üß© Ampliaci√≥n de la Infraestructura HTCondor para el GRID

## üìñ Descripci√≥n

Este proyecto corresponde a una **tesis de pregrado** cuyo prop√≥sito es **proponer un universo para la ampliaci√≥n de la infraestructura HTCondor del Grupo de Investigaci√≥n en Redes, Informaci√≥n y Distribuci√≥n (GRID)** de la **Universidad del Quind√≠o**.

La propuesta busca fortalecer las capacidades de computaci√≥n distribuida del GRID mediante la incorporaci√≥n de un nuevo universo HTCondor, contribuyendo al cumplimiento de sus objetivos misionales de **docencia, investigaci√≥n y extensi√≥n** y democratizando el acceso a recursos de computaci√≥n de alta productividad (HTC) para la comunidad acad√©mica.

---

## üéØ Objetivos

### Objetivo general
Proponer un Universo para la ampliaci√≥n de la infraestructura HTCondor del grupo de investigaci√≥n GRID de la Universidad del Quind√≠o.

### Objetivos espec√≠ficos
- Determinar necesidades, oportunidades y/o problemas (NPO) con relaci√≥n a la infraestructura HTCondor del GRID.
- Identificar, analizar y caracterizar universos HTCondor y seleccionar un universo para la infraestructura del GRID.
- Especificar el dise√±o arquitect√≥nico requerido para la implementaci√≥n del universo HTCondor seleccionado.
- Implementar un prototipo funcional del universo HTCondor seleccionado seg√∫n el dise√±o especificado.
- Validar la implementaci√≥n del universo HTCondor seleccionado seg√∫n las NPO del GRID.

---

## üìö Marco Conceptual

### Computaci√≥n Distribuida
Paradigma computacional que involucra dos o m√°s computadoras conectadas en red que trabajan colaborativamente para compartir y ejecutar tareas computacionales, distribuyendo las cargas de trabajo a trav√©s de m√∫ltiples nodos.

### High Throughput Computing (HTC)
Categor√≠a espec√≠fica de paralelismo computacional caracterizada por ejecutar m√∫ltiples copias id√©nticas de una aplicaci√≥n de manera simult√°nea, enfoc√°ndose en la productividad a largo plazo m√°s que en el rendimiento instant√°neo.

### HTCondor
Sistema especializado de gesti√≥n de cargas de trabajo dise√±ado para trabajos computacionalmente intensivos, que proporciona mecanismos de encolado, pol√≠tica de programaci√≥n, monitoreo de recursos y gesti√≥n distribuida mediante el paradigma de matchmaking y ClassAds.

### Universo HTCondor
Par√°metro de ejecuci√≥n fundamental que define el entorno operativo y el mecanismo de ejecuci√≥n espec√≠fico para una tarea enviada al cl√∫ster. Determina aspectos cr√≠ticos como gesti√≥n de procesos, manejo de archivos, capacidad de checkpointing y el tipo de aplicaci√≥n que puede ejecutarse.

---

## üß™ Metodolog√≠a

La metodolog√≠a se desarroll√≥ en fases sucesivas, siguiendo un enfoque sistem√°tico:

1. **Caracterizaci√≥n del GRID**: An√°lisis de stakeholders, infraestructura actual y necesidades espec√≠ficas.
2. **Identificaci√≥n y an√°lisis de universos**: Caracterizaci√≥n de universos HTCondor disponibles.
3. **Selecci√≥n de universo**: Evaluaci√≥n y selecci√≥n del universo m√°s adecuado para las necesidades del GRID.
4. **Dise√±o arquitect√≥nico**: Especificaci√≥n del dise√±o requerido para la implementaci√≥n.
5. **Implementaci√≥n del prototipo**: Desarrollo de un producto m√≠nimo viable (PMV).
6. **Validaci√≥n**: Pruebas t√©cnicas y retroalimentaci√≥n de usuarios del GRID.

---

## ‚öôÔ∏è Universos HTCondor Evaluados

Los universos HTCondor contemplados en la investigaci√≥n incluyen:

- **Vanilla**: Universo por defecto para ejecuci√≥n de prop√≥sito general
- **Container**: Ejecuci√≥n de aplicaciones en contenedores OCI
- **Docker**: Ejecuci√≥n espec√≠fica de contenedores Docker
- **Java**: Optimizado para aplicaciones Java
- **VM**: Ejecuci√≥n en m√°quinas virtuales
- **Parallel**: Para trabajos paralelos MPI
- **Grid**: Integraci√≥n con recursos de grid computing
- **Scheduler**: Para trabajos de programaci√≥n espec√≠fica
- **Local**: Ejecuci√≥n en recursos locales

---

## üèóÔ∏è Infraestructura Actual del GRID

### Cl√∫ster de Raspberry Pi
- **9 torres** de equipos Raspberry Pi (Torre 1-9)
- **7 equipos por torre** (excepto Torre 1 con 2 equipos)
- **Torre 1**: Nodo maestro y nodo de env√≠o
- **Torres 2-8**: Nodos ejecutores
- **Conectividad**: Switch Cisco SF100D-08 por torre
- **Switch principal**: Cisco SG200-26

### Configuraci√≥n Actual
- **Universo implementado**: Vanilla √∫nicamente
- **Orientaci√≥n**: Ejecuci√≥n no especializada de programas
- **Casos de uso**: Scripts de Shell y aplicaciones de prop√≥sito general

---

## üöÄ Impacto Esperado

### Para el GRID
- Consolidaci√≥n de infraestructura de computaci√≥n distribuida m√°s amplia y capaz
- Incremento en competitividad en el √°mbito de HTC
- Fortalecimiento como referente regional en tecnolog√≠as de computaci√≥n distribuida
- Potenciaci√≥n de colaboraciones interuniversitarias

### Para la Comunidad Acad√©mica
- Democratizaci√≥n del acceso a recursos de computaci√≥n distribuida
- Apoyo a disciplinas que requieren procesamiento intensivo (bioinform√°tica, big data, IA)
- Oportunidades formativas en HTC para estudiantes
- Fortalecimiento de capacidades investigativas institucionales

### Casos de Uso Potenciales
- Simulaciones cient√≠ficas y modelado matem√°tico
- Procesamiento de datos masivos
- An√°lisis bioinform√°tico y gen√≥mico
- Aprendizaje autom√°tico distribuido
- Renderizaci√≥n y procesamiento de im√°genes
- Investigaci√≥n en computaci√≥n de alto rendimiento

---

## üìä Beneficios de la Ampliaci√≥n

- **Versatilidad**: M√∫ltiples ambientes de ejecuci√≥n especializados
- **Eficiencia**: Optimizaci√≥n seg√∫n el tipo de carga de trabajo
- **Escalabilidad**: Capacidad de crecimiento seg√∫n demanda
- **Accesibilidad**: Servicios disponibles 24/7 para la comunidad acad√©mica
- **Formaci√≥n**: Plataforma pr√°ctica para ense√±anza de HTC
- **Investigaci√≥n**: Soporte a proyectos de mayor envergadura computacional
