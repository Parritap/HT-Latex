\ChapterImageStar[cap:marcoConceptual]{Marco Conceptual}{./images/fondo.png}\label{cap:marcoConceptual}
\mbox{}\\

\noindent
Los conceptos a continuación no solo delimitan el ámbito de estudio, sino que también proporcionan las bases terminológicas y estructurales necesarias para la evaluación, comparación e implementación de las tecnologías consideradas.

\noindent
\section{Computación Distribuida}
\noindent
La computación distribuida es un paradigma computacional que involucra dos o más computadoras conectadas en red que trabajan colaborativamente para compartir y ejecutar las mismas tareas computacionales~\citep{Ali2015}. El objetivo fundamental de este enfoque es distribuir las cargas de trabajo a través de múltiples nodos en lugar de depender de una sola máquina. Otra definición similar es brindada por ~\cite{Lamport1990}, los cuales argumentan que la computación distribuida es una actividad  de un sistema distribuido espacialmente, \ie, computación extendida a través del espacio; así mismo dan una definición~\cite{Chang1995}, quienes indican que un sistema de computación distribuida es aquel definido como un conjunto de nodos (o procesadores) ubicados en distintos lugares y conectados por una red. Según~\cite{AWS01}, existen cuatro tipos principales de arquitecturas basadas en computación distribuida: (\textbf{1}) la \textbf{arquitectura cliente-servidor}, donde un servidor centralizado proporciona servicios a múltiples clientes que realizan solicitudes; (\textbf{2}) la \textbf{arquitectura de tres niveles}, que separa la lógica en capas de presentación, aplicación y datos para mejorar la escalabilidad y mantenibilidad; (\textbf{3}) la \textbf{arquitectura de N niveles}, que extiende el modelo anterior incorporando múltiples capas especializadas para manejar diferentes aspectos del procesamiento; y (\textbf{4}) la \textbf{arquitectura \textit{peer-to-peer}}, donde todos los nodos actúan simultáneamente como clientes y servidores, compartiendo recursos de manera descentralizada sin depender de un servidor central.

\section{High Throughput Computing (\HTC)}
\noindent
Para~\cite{Morgan2009}, la Computación de Alta Productividad o \textit{High Throughput Computing} (\HTC) constituye una categoría específica de paralelismo computacional que se caracteriza por ejecutar múltiples copias idénticas de una aplicación de manera simultánea. Así pues, para \cite{Morgan2009} a diferencia del paralelismo de capacidad o ``paralelismo verdadero'', donde los componentes paralelos de una aplicación única se comunican entre sí durante la ejecución, las aplicaciones \HTC~funcionan de manera completamente aislada, requiriendo únicamente una configuración inicial y una comunicación final de resultados. Además, los trabajos \HTC~tienen una naturaleza inherentemente independiente (\ie, no requieren colaboración entre sí), pueden ejecutarse en cualquier orden y pueden ser enviados por distintos usuarios, lo que facilita la gestión distribuida de cargas de trabajo computacionales de gran escala.

\section{Computación de alta productividad \textit{High Performance Computing} \HPC}

\noindent
Según \cite{SK2023}, \HPC~es aquella computación dedicada al procesamiento paralelo de cálculos complejos a altas velocidades a través de múltiples servidores usando grandes volúmenes de datos. Contrario a la filosofía \HTC, en \HPC~se busca maximizar la cantidad de operaciones de punto flotante (\textit{floating point operations per second} o FLOPS) \citep{HTCondor-what-is-htc}. Mientras que \HPC~se concentra en qué tan rápido se completa un trabajo individual, \HTC~se preocupa por cuántos trabajos se pueden ejecutar a lo largo de períodos extendidos de tiempo, como meses o incluso años \citep{Raman1998}. Esta distinción fundamental establece dos paradigmas complementarios: \HPC~busca el rendimiento \textbf{instantáneo}, mientras que \HTC~busca la productividad \textbf{a largo plazo}.

\section{Matchmaking y ClassAds}
Los sistemas Matchmaking y ClassAd fueron desarrollados por \cite{Raman1998}, quienes definen el Matchmaking como un paradigma para la gestión de recursos distribuidos, especialmente orientado a entornos de computación de alto rendimiento. Este paradigma aborda los desafíos inherentes a la naturaleza distribuida de los recursos y la heterogeneidad característica de estos sistemas. De acuerdo con los autores:

\begin{quote}
	Este enfoque se fundamenta en la premisa de que las entidades que proporcionan o requieren servicios anuncian sus características y requisitos mediante anuncios clasificados (\textit{classified advertisements} o ClassAds), los cuales son procesados por un servicio de emparejamiento designado (\textit{matchmaker}) que identifica coincidencias compatibles e informa a las entidades relevantes, cesando posteriormente su responsabilidad en el proceso. La distinción fundamental de este paradigma radica en la separación clara entre las fases de emparejamiento (\textit{matching}) y reclamación (\textit{claiming}), donde el emparejamiento representa una introducción mutua entre entidades compatibles, mientras que la reclamación establece la relación de trabajo efectiva mediante un protocolo independiente que no involucra al \textit{matchmaker} \citep{Raman1998}.
\end{quote}

\noindent
El sistema ClassAd, por su parte, constituye el modelo de datos semi-estructurado que sustenta el framework de matchmaking, caracterizado por su capacidad de representar servicios arbitrarios y restricciones de asignación sin requerir un esquema específico predefinido~\cite{Raman1998}. Según los autores:
\begin{quote}
	Los ClassAds integran el lenguaje de consulta directamente en el modelo de datos, permitiendo que las restricciones y consultas se expresen como atributos de los propios anuncios, lo que facilita la operación en entornos heterogéneos donde tanto los proveedores de recursos como los clientes pueden imponer restricciones mutuas sobre las entidades con las que están dispuestos a interactuar. Esta arquitectura permite la evaluación de expresiones en un entorno donde cada ClassAd puede acceder a los atributos del otro mediante referencias del tipo ``self.attribute'' y ``other.attribute'', facilitando así la especificación de políticas de uso sofisticadas y dinámicas que se adaptan a las condiciones cambiantes del sistema distribuido \cite{Raman1998}.
\end{quote}

\section{HTCondor}
\noindent
HTCondor es un sistema especializado de gestión de cargas de trabajo diseñado específicamente para trabajos computacionalmente intensivos y enfocado en el paradigma \HTC. Como está expuesto en su página web \citep{HTCondor-what-is-HTCondor}, como otros sistemas de procesamiento por lotes completos, HTCondor proporciona un mecanismo de encolado de trabajos, política de programación, esquema de prioridades, monitoreo de recursos y gestión de recursos. Los usuarios envían sus trabajos seriales o paralelos a HTCondor, que los coloca en una cola, decide cuándo y dónde ejecutar los trabajos basándose en una política específica, monitorea cuidadosamente su progreso e informa al usuario una vez completados \citep{HTCondor-what-is-HTCondor}. La arquitectura innovadora de HTCondor le permite tener éxito en áreas donde los sistemas de programación tradicionales fallan, ya que puede gestionar tanto clústeres de nodos de computación dedicados como aprovechar eficazmente la potencia de \CPU~desperdiciada de estaciones de trabajo de escritorio inactivas. Además, HTCondor incorpora el mecanismo ClassAd que proporciona un marco extremadamente flexible y expresivo para emparejar solicitudes de recursos (trabajos) con ofertas de recursos (máquinas), permitiendo que tanto los trabajos como las máquinas especifiquen requisitos y preferencias de manera sofisticada.

Según la documentación oficial \citep{HTCondor-roles}, en un \textit{pool} de HTCondor, cada máquina puede configurarse para desempeñar uno o más de los siguientes roles fundamentales: el Gestor Central (\textit{master}), el Punto de Acceso (\textit{submit}) y el Punto de Ejecución (\textit{worker}. Estos roles definen las funciones y responsabilidades específicas de cada nodo dentro de la arquitectura distribuida del sistema. Según dicta el manual de \cite{HTCondor-roles}, la descripción de cada rol es como sigue.

El rol más crítico en la arquitectura de HTCondor corresponde al \textbf{Gestor Central} (\textbf{\textit{Central Manager}}). La máquina con este rol tiene la responsabilidad de ejecutar el algoritmo de emparejamiento entre las solicitudes de recursos generadas por los trabajos encolados y los recursos computacionales disponibles en las máquinas de ejecución. El proceso de negociación es orquestado por su demonio principal, \textit{condor\_negotiator}, que implementa las políticas de asignación del sistema. Dada su función coordinadora, el Gestor Central debe desplegarse en una máquina con alta disponibilidad y conectividad de red óptima hacia todos los equipos del \textit{pool}, ya que constituye el punto focal de comunicación para las actualizaciones periódicas de estado provenientes de todos los nodos participantes.

El segundo rol arquitectónico corresponde al \textbf{Punto de Acceso} (\textbf{\textit{Access Point}} o \textit{submit}). Las máquinas configuradas con este rol constituyen la interfaz mediante la cual los usuarios interactúan con la infraestructura HTCondor para someter trabajos al sistema de colas. El demonio \textit{condor\_schedd}, ejecutándose en estos nodos, es responsable de la gestión integral de la cola de trabajos, incluyendo la planificación temporal y la coordinación de las transferencias de archivos de entrada y salida. A diferencia del Gestor Central---cuya singularidad es requisito arquitectónico---pueden coexistir múltiples Puntos de Acceso en un mismo \textit{pool}, facilitando así la escalabilidad horizontal del sistema. Los nodos con este rol deben provisionarse, en lo posible, con abundantes recursos de memoria y capacidad de procesamiento, considerando que por cada nodo ejecutor se instancia un demonio \textit{condor\_shadow} asociado, lo cual puede resultar en demandas significativas de recursos bajo condiciones de alta concurrencia.

El tercer rol fundamental es el de \textbf{Punto de Ejecución} (\textbf{\textit{Execution Point}} o \textit{worker}). Las máquinas configuradas bajo este perfil proveen los recursos computacionales efectivos---ciclos de CPU, memoria RAM, almacenamiento temporal---requeridos para la ejecución material de los trabajos sometidos a HTCondor. El demonio \textit{condor\_startd}, ejecutándose en estos nodos, se encarga de publicar periódicamente la disponibilidad de recursos hacia el Gestor Central mediante mensajes \textit{ClassAd}. Cuando el proceso de negociación resulta en la asignación de un trabajo al nodo, se instancia dinámicamente un proceso \textit{condor\_starter} que asume la responsabilidad de establecer el entorno de ejecución apropiado (\textit{sandbox}), supervisar el ciclo de vida del trabajo y gestionar su terminación. Este rol constituye la clase más poblada en un \textit{pool} típico, pudiendo abarcar desde decenas hasta decenas de miles de máquinas de ejecución en instalaciones de gran escala.

Resulta imperativo destacar que estos roles no son mutuamente exclusivos. Una única máquina física puede ser configurada para desempeñar múltiples roles de forma concurrente, configuración que resulta típica en despliegues de HTCondor de escala reducida o para propósitos de desarrollo y pruebas.\section{Universo}
\noindent
En el contexto del sistema de cómputo distribuido HTCondor, un universo constituye un parámetro de ejecución fundamental que define el entorno operativo y el mecanismo de ejecución específico para una tarea (\textit{job}) enviada al clúster. La documentación oficial del proyecto establece que:

\begin{quote}
	El universo representa el atributo más importante de un trabajo, ya que determina gran parte del comportamiento del sistema HTCondor al gestionar dicho trabajo \citep{HTCondor-what-is-a-job}.
\end{quote}

\noindent
Esta elección configura aspectos críticos como la gestión de procesos, el manejo de archivos, la capacidad de \textit{checkpointing} y migración, e incluso el tipo de aplicación que puede ser ejecutada. Los universos disponibles permiten ejecutar desde binarios estándar y trabajos paralelos MPI hasta máquinas virtuales, contenedores Docker o aplicaciones Java. La diversidad de universos HTCondor incluye opciones como \textit{vanilla} (universo por defecto), \textit{parallel}, \textit{grid}, \textit{container}, \textit{docker}, \textit{java}, \textit{vm}, entre otros, cada uno optimizado para tipos específicos de cargas de trabajo. Por lo tanto, la selección del universo adecuado trasciende la configuración por defecto y constituye un requisito indispensable para garantizar la compatibilidad, eficiencia y éxito en la ejecución de cargas de trabajo heterogéneas en la infraestructura distribuida.
