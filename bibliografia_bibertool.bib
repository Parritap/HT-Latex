@MISC{HTCondor,
  AUTHOR = {{HTCondor Team}},
  ORGANIZATION = {HTCondor},
  URL = {https://htcondor.org/htcondor/overview/},
  DATE = {s.f},
  NOTE = {Retrieved September 29, 2024},
  TITLE = {HTCondor Overview},
}

@MISC{AWS01,
  AUTHOR = {{Amazon Web Services, Inc.}},
  DATE = {s.f.},
  HOWPUBLISHED = {\url{https://aws.amazon.com/what-is/distributed-computing/}},
  NOTE = {Accessed: 2024-09-28},
  TITLE = {What is Distributed Computing?},
}

@MISC{HTCondor-what-is-HTCondor,
  AUTHOR = {{HTCondor Team\phantom{}}},
  DATE = {s.f.},
  HOWPUBLISHED = {\url{https://htcondor.org/description.html}},
  NOTE = {[Accessed 28-09-2025]},
  TITLE = {{W}hat is {H}{T}{C}ondor? --- htcondor.org},
}

@ARTICLE{Manzoor2020,
  ABSTRACT = {Cloud computing has become a very important computing model to process data and execute computationally concentrated applications in pay-per-use method. Resource allocation is a process in which the resources are allocated to consumers by cloud providers based on their flexible requirements. As the data is expanding every day, allocating resources efficiently according to the consumer demand has also become very important, keeping Service Level Agreement (SLA) between service providers and consumers in prospect. This task of resource allocation becomes more challenging due to finite available resources and increasing consumer demands. Therefore, many unique models and techniques have been proposed to allocate resources efficiently. In the light of the uniqueness of the models and techniques, the main aim of the resource allocation is to limit the overhead/expenses associated with it. This research aims to present a comprehensive, structured literature review on different aspects of resource allocation in cloud computing, including strategic, target resources, optimization, scheduling and power. More than 50 articles, between year 2007 and 2019, related to resource allocation in cloud computing have been shortlisted through a structured mechanism and they are reviewed under clearly defined objectives. It presents a topical taxonomy of resource allocation dimensions, and articles under each category are discussed and analysed. Lastly, salient future directions in this area are discussed.},
  AUTHOR = {Manzoor, Shahida and Ullah, Zahid and Jeon, Gwanggil},
  URL = {https://eejournal.ktu.lt/index.php/elt/article/view/25865},
  DATE = {2020-12},
  DOI = {10.5755/j01.eie.26.6.25865},
  JOURNALTITLE = {Elektronika ir Elektrotechnika},
  NUMBER = {6},
  PAGES = {40--51},
  TITLE = {Resource Allocation Techniques in Cloud Computing: A Review and Future Directions},
  VOLUME = {26},
}

@ARTICLE{Oldham1995,
  AUTHOR = {Chang, H.W.D. and Oldham, W.J.B.},
  DATE = {1995},
  DOI = {10.1109/71.476170},
  JOURNALTITLE = {IEEE Transactions on Parallel and Distributed Systems},
  KEYWORDS = {Distributed computing;Distributed control;Simulated annealing;Application software;Resource management;Hardware;Computer architecture;Transport protocols;Throughput;Computational modeling},
  NUMBER = {12},
  PAGES = {1301--1315},
  TITLE = {Dynamic task allocation models for large distributed computing systems},
  VOLUME = {6},
}

@ARTICLE{Thain2005,
  ABSTRACT = {Since 1984, the Condor project has enabled ordinary users to do extraordinary computing. Today, the project continues to explore the social and technical problems of cooperative computing on scales ranging from the desktop to the world-wide computational Grid. In this paper, we provide the history and philosophy of the Condor project and describe how it has interacted with other projects and evolved along with the field of distributed computing. We outline the core components of the Condor system and describe how the technology of computing must correspond to social structures. Throughout, we reflect on the lessons of experience and chart the course travelled by research ideas as they grow into production systems. Copyright © 2005 John Wiley \& Sons, Ltd.},
  AUTHOR = {Thain, Douglas and Tannenbaum, Todd and Livny, Miron},
  LOCATION = {GBR},
  PUBLISHER = {John Wiley and Sons Ltd.},
  DATE = {2005-02},
  ISSN = {1532-0626},
  JOURNALTITLE = {Concurr. Comput.: Pract. Exper.},
  KEYWORDS = {split execution,scheduling,planning,history,community,Grid,Condor},
  NUMBER = {2–4},
  PAGES = {323--356},
  TITLE = {Distributed computing in practice: the Condor experience: Research Articles},
  VOLUME = {17},
}

@INPROCEEDINGS{Raman1998,
  AUTHOR = {Raman, R. and Livny, M. and Solomon, M.},
  BOOKTITLE = {Proceedings. The Seventh International Symposium on High Performance Distributed Computing (Cat. No.98TB100244)},
  DATE = {1998},
  DOI = {10.1109/HPDC.1998.709966},
  KEYWORDS = {Resource management;Throughput;Robustness;Processor scheduling;Centralized control;Distributed computing;Data models;Specification languages;Protocols;Computer architecture},
  PAGES = {140--146},
  TITLE = {Matchmaking: distributed resource management for high throughput computing},
}

@BOOK{Landau2005,
  AUTHOR = {Landu, RUBIN H. and Wangberg, Robyn and Augustson, Kyle and Páez, M. J. and Bordeianu, C. C. and Barnes, C.},
  PUBLISHER = {Princeton University Press},
  URL = {http://www.jstor.org/stable/j.ctvcm4grd},
  DATE = {2005},
  ISBN = {9780691121833},
  TITLE = {A First Course in Scientific Computing: Symbolic, Graphic, and Numeric Modeling Using Maple, Java, Mathematica, and Fortran90},
  URLDATE = {2025-07-29},
}

@INCOLLECTION{Lamport1990,
  ABSTRACT = {Publisher Summary Distributed computing is an activity that is performed on a spatially distributed system. An important problem in distributed computing is to provide a user with a non-distributed view of a distributed system to implement a distributed file system that allows the client programmer to ignore the physical location of his data. The models of computation generally considered to be distributed are process models in which the computational activity is represented as the concurrent execution of sequential processes. Different process models are distinguished by the mechanism employed for inter-process communication. The process models that are most distributed are the ones in which processes communicate by message passing. A process sends a message by adding it to a message queue and another process receives the message by removing it from the queue. There are two basic complexity measures for distributed algorithms: time and message complexity. The time complexity of an algorithm measures the time needed both for message transmission and for computation within the processes. The most common measure of message complexity is the total number of messages transmitted. If messages contain on the order of a few hundred bits or more, then the total number of bits sent might be a better measure of the cost than the number of messages.},
  AUTHOR = {Lamport, Leslie and Lynch, Nancy},
  EDITOR = {{VAN LEEUWEN}, JAN},
  LOCATION = {Amsterdam},
  PUBLISHER = {Elsevier},
  URL = {https://www.sciencedirect.com/science/article/pii/B9780444880741500238},
  BOOKTITLE = {Formal Models and Semantics},
  DATE = {1990},
  DOI = {https://doi.org/10.1016/B978-0-444-88074-1.50023-8},
  ISBN = {978-0-444-88074-1},
  PAGES = {1157--1199},
  SERIES = {Handbook of Theoretical Computer Science},
  TITLE = {CHAPTER 18 - Distributed Computing: Models and Methods},
}

@INPROCEEDINGS{Juve2015,
  AUTHOR = {Juve, Gideon and Tovar, Benjamin and Da Silva, Rafael Ferreira and Krol, Dariusz and Thain, Douglas and Deelman, Ewa and Allcock, William and Livny, Miron},
  BOOKTITLE = {2015 IEEE International Conference on Cluster Computing},
  DATE = {2015},
  DOI = {10.1109/CLUSTER.2015.115},
  KEYWORDS = {Monitoring;Libraries;Linux;Kernel;Probes;Radiation detectors;High-Throughput Computing;Profiling;Monitoring},
  PAGES = {650--657},
  TITLE = {Practical Resource Monitoring for Robust High Throughput Computing},
}

@INCOLLECTION{Morgan2009,
  ABSTRACT = {While it is true that the modern computer is many orders of magnitude faster than that of yesteryear; this tremendous growth in CPU clock rates is now over. Unfortunately, however, the growth in demand for computational power has not abated; whereas researchers a decade ago could simply wait for computers to get faster, today the only solution to the growing need for more powerful computational resource lies in the exploitation of parallelism. Software parallelization falls generally into two broad categories—“true parallel” and high-throughput computing. This chapter focuses on the latter of these two types of parallelism. With high-throughput computing, users can run many copies of their software at the same time across many different computers. This technique for achieving parallelism is powerful in its ability to provide high degrees of parallelism, yet simple in its conceptual implementation. This chapter covers various patterns of high-throughput computing usage and the skills and techniques necessary to take full advantage of them. By utilizing numerous examples and sample codes and scripts, we hope to provide the reader not only with a deeper understanding of the principles behind high-throughput computing, but also with a set of tools and references that will prove invaluable as she explores software parallelism with her own software applications and research.},
  AUTHOR = {Morgan, Mark and Grimshaw, Andrew},
  EDITOR = {Johnson, Michael L. and Brand, Ludwig},
  PUBLISHER = {Academic Press},
  URL = {https://www.sciencedirect.com/science/article/pii/S0076687909670087},
  BOOKTITLE = {Computer Methods Part B},
  DATE = {2009},
  DOI = {https://doi.org/10.1016/S0076-6879(09)67008-7},
  ISSN = {0076-6879},
  PAGES = {197--227},
  SERIES = {Methods in Enzymology},
  TITLE = {Chapter 8 - High-Throughput Computing in the Sciences},
  VOLUME = {467},
}

@ARTICLE{SK2023,
  AUTHOR = {Sudha, SK and Aji, S},
  DATE = {2024},
  JOURNALTITLE = {Cloud Computing and Data Science},
  PAGES = {50--61},
  TITLE = {Exploring the advancements in high-performance computing paradigm for remote sensing big data analytics},
}

@INCOLLECTION{Salama2017,
  ABSTRACT = {Self-adaptation has been driven by the need to achieve and maintain quality attributes in the face of the continuously changing requirements, as well as the uncertain demand during run-time. Designing architectures that exhibit a good trade-off between multiple quality attributes is challenging, especially in the case of self-adaptive software systems, due to the complexity, heterogeneity, and ultra-large scale of modern software systems. This challenge increases with the dynamic, open, and uncertain operating environment, as well as the need for complying to environmental, regulatory, and sustainability requirements; such as energy consumption regulations. This study aims at analyzing the research landscape that have explicitly addressed trade-offs management for self-adaptive software architectures, to obtain a comprehensive overview on the current state of research on this specialized area. A systematic mapping study was conducted to identify and analyze research works related to analyzing and managing trade-offs to support decision-making for self-adaptive software architectures. Twenty primary studies were evidently selected and analyzed to classify software paradigms, quality attributes considered, and the self-* properties that drive trade-offs management. The results show constant interest in finding solutions for trade-offs management at design-time and run-time, as well as the success of research initiatives even when new research challenges are found. The findings call for foundational framework to analyze and manage trade-offs for self-adaptive software architectures that can explicitly consider specific multiple quality attributes, the run-time dynamics, the uncertainty of the environment and the complex challenges of modern, ultra-large scale systems in particular given software paradigms.},
  AUTHOR = {Salama, M. and Bahsoon, R. and Bencomo, N.},
  EDITOR = {Mistrik, Ivan and Ali, Nour and Kazman, Rick and Grundy, John and Schmerl, Bradley},
  LOCATION = {Boston},
  PUBLISHER = {Morgan Kaufmann},
  URL = {https://www.sciencedirect.com/science/article/pii/B9780128028551000113},
  BOOKTITLE = {Managing Trade-Offs in Adaptable Software Architectures},
  DATE = {2017},
  DOI = {https://doi.org/10.1016/B978-0-12-802855-1.00011-3},
  ISBN = {978-0-12-802855-1},
  KEYWORDS = {Self-adaptation,Self-adaptive architecture,Software architecture,Trade-offs management,Systematic mapping study,Self-awareness,Long-living software},
  PAGES = {249--297},
  TITLE = {Chapter 11 - Managing Trade-offs in Self-Adaptive Software Architectures: A Systematic Mapping Study},
}

@BOOK{Tanenbaum2015,
  AUTHOR = {Tanenbaum, Andrew S. and Bos, Herbert},
  LOCATION = {Boston},
  PUBLISHER = {Pearson},
  DATE = {2015},
  EDITION = {4},
  ISBN = {978-0133591620},
  TITLE = {Modern Operating Systems},
}

@ARTICLE{PerezMiguel2013,
  ABSTRACT = {In this work, we present a proposal to build a high throughput computing system totally based upon the Peer-to-Peer (P2P) paradigm. We discuss the general characteristics of P2P systems, with focus on P2P storage, and the expected characteristics of the HTC system: totally decentralized, not requiring permanent connection, and able to implement scheduling policies such as running jobs in a (non-strict) FCFS order. We have selected Cassandra as the supporting P2P storage system for our purposes. We discuss the basic aspects of the system implementation, and carry out some experiments designed to verify that it works as expected.},
  AUTHOR = {Pérez-Miguel, Carlos and Miguel-Alonso, Jose and Mendiburu, Alexander},
  URL = {https://www.sciencedirect.com/science/article/pii/S0167739X11001506},
  DATE = {2013},
  DOI = {https://doi.org/10.1016/j.future.2011.08.011},
  ISSN = {0167-739X},
  JOURNALTITLE = {Future Generation Computer Systems},
  KEYWORDS = {Peer-to-peer networks,High throughput computing,Distributed hash tables},
  NOTE = {Including Special section: AIRCC-NetCoM 2009 and Special section: Clouds and Service-Oriented Architectures},
  NUMBER = {1},
  PAGES = {352--360},
  TITLE = {High throughput computing over peer-to-peer networks},
  VOLUME = {29},
}

@INBOOK{Nielsen2016,
  AUTHOR = {Nielsen, Frank},
  DATE = {2016-02},
  DOI = {10.1007/978-3-319-21903-5_2},
  ISBN = {978-3-319-21902-8},
  PAGES = {21--62},
  TITLE = {Introduction to MPI: The Message Passing Interface},
}

@INPROCEEDINGS{Wilson2016,
  ABSTRACT = {The majority of university courses which educate students in high performance, parallel, and distributed computing are located within computer science departments. This can potentially be a hurdle to students from other disciplines who need to acquire these critical skills.We discuss a sequence of application-driven courses designed to educate undergraduate and graduate students who do not necessarily have a computer science background on developing scientific research software, with an emphasis on using high performance, parallel, and distributed computational systems.},
  AUTHOR = {Wilson, Lucas A. and Dey, S. Charlie},
  LOCATION = {Salt Lake City, Utah},
  PUBLISHER = {IEEE Press},
  BOOKTITLE = {Proceedings of the Workshop on Education for High Performance Computing},
  DATE = {2016},
  ISBN = {9781509038275},
  PAGES = {19--24},
  SERIES = {EduHPC '16},
  TITLE = {Computational science education focused on future domain scientists},
}

@INPROCEEDINGS{Bianchi2013,
  AUTHOR = {Bianchi, Oscar Martín and Ariznabarreta Fossati, José Ignacio and Repetto, Alejandro Juan Manuel},
  LANGUAGE = {Spanish},
  LOCATION = {Red de Universidades con Carreras en Informática (RedUNCI)},
  URL = {http://sedici.unlp.edu.ar/handle/10915/27283},
  BOOKTITLE = {XV Workshop de Investigadores en Ciencias de la Computación},
  DATE = {2013-06},
  NOTE = {Exposición: abril 2013},
  PAGES = {652--657},
  TITLE = {Construyendo un sistema de cómputo distribuido multipropósito},
}

@ARTICLE{Tsai2015,
  ABSTRACT = {The age of big data is now coming. But the traditional data analytics may not be able to handle such large quantities of data. The question that arises now is, how to develop a high performance platform to efficiently analyze big data and how to design an appropriate mining algorithm to find the useful things from big data. To deeply discuss this issue, this paper begins with a brief introduction to data analytics, followed by the discussions of big data analytics. Some important open issues and further research directions will also be presented for the next step of big data analytics.},
  AUTHOR = {Tsai, Chun-Wei and Lai, Chin-Feng and Chao, Han-Chieh and Vasilakos, Athanasios V.},
  URL = {https://doi.org/10.1186/s40537-015-0030-3},
  DATE = {2015-10-01},
  DOI = {10.1186/s40537-015-0030-3},
  ISSN = {2196-1115},
  JOURNALTITLE = {Journal of Big Data},
  NUMBER = {1},
  PAGES = {21},
  TITLE = {Big data analytics: a survey},
  VOLUME = {2},
}

@INPROCEEDINGS{Thomson2023,
  AUTHOR = {Thompson, Neil and Greenewald, Kristjan and Lee, Keeheon and Manso, Gabriel F.},
  ORGANIZATION = {LIMITS},
  BOOKTITLE = {Ninth {Computing} within {Limits} 2023},
  DATE = {2023-06},
  NOTE = {https://limits.pubpub.org/pub/wm1lwjce},
  TITLE = {The {Computational} {Limits} of {Deep} {Learning}},
}

@MANUAL{HTCondor-what-is-htc,
  AUTHOR = {{HTCondor Team\phantom{}\phantom{} }},
  ORGANIZATION = {HTCondor Project},
  URL = {https://htcondor.readthedocs.io/en/latest/overview/high-throughput-computing-requirements.html},
  DATE = {2025-09},
  NOTE = {HTCondor Manual, accessed 2025-09-28},
  TITLE = {High-Throughput Computing (HTC) and its Requirements},
  VERSION = {24.12.4},
}

@ARTICLE{Ali2015,
  AUTHOR = {Ali, Md Firoj and Khan, Rafiqul Zaman},
  PUBLISHER = {Eswar Publications},
  DATE = {2015},
  JOURNALTITLE = {International Journal of Advanced Networking and Applications},
  NUMBER = {1},
  PAGES = {2630},
  TITLE = {Distributed computing: An overview},
  VOLUME = {7},
}

@ARTICLE{Chang1995,
  AUTHOR = {Chang, H.W.D. and Oldham, W.J.B.},
  DATE = {1995},
  DOI = {10.1109/71.476170},
  JOURNALTITLE = {IEEE Transactions on Parallel and Distributed Systems},
  KEYWORDS = {Distributed computing;Distributed control;Simulated annealing;Application software;Resource management;Hardware;Computer architecture;Transport protocols;Throughput;Computational modeling},
  NUMBER = {12},
  PAGES = {1301--1315},
  TITLE = {Dynamic task allocation models for large distributed computing systems},
  VOLUME = {6},
}

@MISC{HTCondor-what-is-a-job,
  AUTHOR = {{HTCondor Team\phantom{}\phantom{}\phantom{}}},
  DATE = {s.f.},
  HOWPUBLISHED = {\url{https://htcondor.readthedocs.io/en/24.x/users-manual/quick-start-guide.html#what-is-a-job}},
  NOTE = {[Accessed 28-09-2025]},
  TITLE = {{HTCondor User Manual: Quick Start Guide -- What Is a Job?}},
}

@MISC{HTCondor-choosing-universe,
  AUTHOR = {{HTCondor Team\phantom{}\phantom{}\phantom{}\phantom{}}},
  URL = {https://htcondor.readthedocs.io/en/lts/users-manual/choosing-an-htcondor-universe.html},
  DATE = {2025},
  HOWPUBLISHED = {HTCondor Manual},
  NOTE = {Accedido el 2025-10-02},
  TITLE = {Choosing an {HTCondor} Universe},
  URLDATE = {2025-10-02},
}

@BOOK{PMI2019,
  AUTHOR = {{Project Management Institute}},
  LOCATION = {Newtown Square, PA},
  PUBLISHER = {Project Management Institute},
  URL = {https://books.google.com.co/books?id=MNRHAQAACAAJ},
  DATE = {2019},
  EDITION = {6},
  ISBN = {978-1628255848},
  TITLE = {Guía de los fundamentos para la dirección de proyectos (Guía del PMBOK)},
}

@MISC{Spray2023,
  AUTHOR = {Spray, J. R.},
  DATE = {2023},
  HOWPUBLISHED = {\url{http://abstractionlayeredarchitecture.com/}},
  NOTE = {Accessed: 2025-09-25},
  TITLE = {Abstraction Layered Architecture},
}

@INPROCEEDINGS{Mumtaza2025,
  AUTHOR = {Mumtaza, Farisa Fikri and Mulyana, Rahmat and Mukti, Iqbal Yulizar},
  BOOKTITLE = {2025 International Conference on Advancement in Data Science, E-learning and Information System (ICADEIS)},
  DATE = {2025},
  DOI = {10.1109/ICADEIS65852.2025.10933402},
  KEYWORDS = {Digital transformation;Standards organizations;Merging;Banking;Organizations;Planning;Interviews;Faces;Investment;Information systems;BPR;digital transformation;enterprise architecture;SMEs;TOGAF},
  PAGES = {1--7},
  TITLE = {Utilizing TOGAF 10 to Design an Enterprise Architecture for BPRBCo SME Digital Transformation},
}

@MISC{ISO25010,
  AUTHOR = {{International Organization for Standardization}},
  LOCATION = {Geneva, Switzerland},
  DATE = {2011},
  HOWPUBLISHED = {Standard},
  TITLE = {{ISO/IEC} 25010:2011, Systems and software engineering — Systems and software Quality Requirements and Evaluation (SQuaRE) — System and software quality models},
}

@MISC{SMSBuilder2020,
  AUTHOR = {Candela-Uribe, C.A. and Sepúlveda-Rodríguez, L.E. and Chavarro-Porras, J.C. and Sanabria-Ordoñez, J.A. and Garrido, J.L. and Rodríguez-Domínguez, C. and Guerrero-Contreras, G.},
  DATE = {2020},
  HOWPUBLISHED = {\url{https://github.com/grid-uq/sms-builder}},
  NOTE = {Accessed: 2025-08-11},
  TITLE = {SMS-Builder Project},
}

@MISC{sms-builder-own-container,
  AUTHOR = {Candela-Uribe, C.A. and J, L.E. and Chavarro-Porras, J.C. and Parra Parra, J.E. and Castaño Osma, J.E.},
  URL = {https://hub.docker.com/r/parritap/sms-htcondor-universes},
  DATE = {2025},
  TITLE = {SMS-builder project},
}

@BOOK{landau01,
  AUTHOR = {Landu, Rubin H. and Wangberg, Robyn and Augustson, Kyle and Páez, M. J. and Bordeianu, C. C. and Barnes, C.},
  PUBLISHER = {Princeton University Press},
  URL = {http://www.jstor.org/stable/j.ctvcm4grd},
  DATE = {2005},
  ISBN = {9780691121833},
  TITLE = {A First Course in Scientific Computing: Symbolic, Graphic, and Numeric Modeling Using Maple, Java, Mathematica, and Fortran90},
  URLDATE = {2025-07-29},
}

@INPROCEEDINGS{juve-01,
  AUTHOR = {Juve, Gideon and Tovar, Benjamin and Da Silva, Rafael Ferreira and Krol, Dariusz and Thain, Douglas and Deelman, Ewa and Allcock, William and Livny, Miron},
  BOOKTITLE = {2015 IEEE International Conference on Cluster Computing},
  DATE = {2015},
  DOI = {10.1109/CLUSTER.2015.115},
  KEYWORDS = {Monitoring;Libraries;Linux;Kernel;Probes;Radiation detectors;High-Throughput Computing;Profiling;Monitoring},
  PAGES = {650--657},
  TITLE = {Practical Resource Monitoring for Robust High Throughput Computing},
}

@ARTICLE{Senol-01,
  ABSTRACT = {In this paper, developments in digital computer technology since the early Fifties are reviewed briefly, and the parallelism which exists between these developments and developments in analysis and design procedures of structural engineering is identified. The recent trends in digital computer technology are examined in order to establish the fact that distributed processing is now an accepted philosophy for further developments. The impact of this on the analysis and design practices of structural engineering is assessed by first examining these practices from a data processing standpoint to identify the key operations and data bases, and then fitting them to the characteristics of distributed processing. The merits and drawbacks of the present philosophy in educating structural engineers are discussed and projections are made for the industry-academia relations in the distributed processing environment of structural analysis and design. An ongoing experiment of distributed computing in a University environment is described.},
  AUTHOR = {Utku, Senol and Lestingi, Joseph and Salama, Moktar},
  URL = {https://www.sciencedirect.com/science/article/pii/0045794982900621},
  DATE = {1982},
  DOI = {https://doi.org/10.1016/0045-7949(82)90062-1},
  ISSN = {0045-7949},
  JOURNALTITLE = {Computers \& Structures},
  NUMBER = {2},
  PAGES = {149--156},
  TITLE = {The impact of distributed computing on education},
  VOLUME = {15},
}

@INPROCEEDINGS{chang-01,
  AUTHOR = {Liu, Chang and Zhao, Zhiwen and Liu, Fang},
  BOOKTITLE = {2009 International Symposium on Computer Network and Multimedia Technology},
  DATE = {2009},
  DOI = {10.1109/CNMT.2009.5374622},
  KEYWORDS = {Read-write memory;Random access memory;Resource management;Information science;Computer architecture;Batch production systems;Job shop scheduling;Processor scheduling;Computerized monitoring;Computer industry},
  PAGES = {1--4},
  TITLE = {An Insight into the Architecture of Condor - A Distributed Scheduler},
}

@MISC{htcondor-description,
  AUTHOR = {{Center for High Throughput Computing}},
  INSTITUTION = {University of Wisconsin--Madison},
  URL = {https://htcondor.org/description.html},
  DATE = {2025},
  HOWPUBLISHED = {\url{https://htcondor.org/description.html}},
  NOTE = {Accessed: July 30, 2025},
  TITLE = {What is {HTCondor}?},
}

@MANUAL{CERNBatchDocs,
  AUTHOR = {{CERN IT Department}},
  ORGANIZATION = {CERN},
  URL = {https://batchdocs.web.cern.ch/index.html},
  DATE = {2025},
  HOWPUBLISHED = {\url{https://batchdocs.web.cern.ch/index.html}},
  NOTE = {Documentation for the CERN IT Batch Service based on HTCondor},
  TITLE = {CERN Batch Service User Guide},
}

@MANUAL{HTCondor-roles,
  AUTHOR = {{HTCondor Team\phantom{}\phantom{}\phantom{}\phantom{}\phantom{}}},
  ORGANIZATION = {University of Wisconsin–Madison},
  URL = {https://htcondor.readthedocs.io/en/latest/admin-manual/introduction-admin-manual.html},
  DATE = {2025},
  NOTE = {Accessed: 2025-10-07},
  TITLE = {HTCondor Administrator Manual},
  URLDATE = {2025-10-07},
}

@MISC{Emilio_DockerHTCondor,
  AUTHOR = {Emilio, Carlo},
  ORGANIZATION = {ABP Computing @ CERN},
  DATE = {s.f},
  HOWPUBLISHED = {A guide published on the CERN ABP Computing website, available at \url{https://abpcomputing.web.cern.ch/guides/docker_on_htcondor/}},
  NOTE = {Accessed: October 6, 2025},
  TITLE = {{Docker on HTCondor}},
}

@MANUAL{HTCondor_Parallel,
  AUTHOR = {{HTCondor Team\phantom{}\phantom{}\phantom{}\phantom{}\phantom{}\phantom{}}},
  ORGANIZATION = {Center for High Throughput Computing, University of Wisconsin-Madison},
  URL = {https://htcondor.readthedocs.io/en/v10_0/users-manual/parallel-applications.html},
  DATE = {2020},
  NOTE = {HTCondor Manual, Users' Manual Chapter. Version 10.0.9 documentation.},
  TITLE = {{Parallel Applications (Including MPI Applications)}},
}

@ARTICLE{Thain2002,
  AUTHOR = {Thain, Douglas and Tannenbaum, Todd and Livny, Miron},
  PUBLISHER = {John Wiley \& Sons, Ltd.},
  URL = {https://research.cs.wisc.edu/htcondor/doc/condorgrid.pdf},
  DATE = {2002},
  JOURNALTITLE = {Concurrency and Computation: Practice and Experience},
  NOTE = {Chapter, Originally published as Concurrency: Pract. Exper. 2002},
  PAGES = {0--20},
  TITLE = {Condor and the Grid},
}

@MISC{HTCondor-env-services,
  AUTHOR = {{HTCondor Team}},
  DATE = {s.f.},
  HOWPUBLISHED = {\url{https://htcondor.readthedocs.io/en/lts/users-manual/env-of-job.html#parallel-jobs-including-mpi-jobs}},
  NOTE = {[Accessed 07-10-2025]},
  TITLE = {{E}nvironment and services for a running job --- {H}{T}{C}ondor {M}anual 25.0.1 documentation --- htcondor.readthedocs.io},
}

@ONLINE{HTCondor_vm_universe_wiki,
  AUTHOR = {{HTCondor Team}},
  ORGANIZATION = {University of Wisconsin--Madison},
  URL = {https://htcondor-wiki.cs.wisc.edu/index.cgi/wiki?p=VmUniverse},
  DATE = {2025},
  NOTE = {Wiki page; provides a comprehensive design outline for the vm-universe in HTCondor},
  TITLE = {HTCondorWiki: Vm Universe},
  URLDATE = {2025-10-08},
}

